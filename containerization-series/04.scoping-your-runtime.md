# Containerizing IBM ACE: A Blog Series - Scoping your runtimes

Packing containers isn’t complicated, right? Just throw everything in there. Well, it is. Until it isn’t. Stack too much 
in one and you overload. Mix fragile with flammable and things get risky. Leave half of it empty and you're wasting capacity. Sound familiar?

Let’s be real. “One app per container” sounds clean on paper, but you’d be staring at hundreds of containers before lunch.
So you bundle. But how?

The trick is knowing what belongs together and what absolutely doesn't. This post lays out the logic. Grounded, brutal, 
and battle-tested. How to scope your runtimes without blowing up performance, security, or your own sanity.


## Performance and startup

Some loads are just heavy. You don't toss an engine block into a shipping container without expecting extra handling, 
extra time, and a few complaints from whoever has to lift it. Same goes for big schemas. They blow up compile times and 
drag out cold starts.
That first sentence probably deserves a _that’s what she said_, but we’re being professional. Mostly.

So what do you do? You front-load the work. Compile at build time, not runtime. Get those hits out of the way before 
anything lands in prod. Track cold start behavior in test or UAT. Know what it costs to spin something up. Set a 
threshold that makes sense for your environment, and alert when you blow past it.
Curious how to do that? I blogged about that: [Bar Build Commands: Unraveling the Differences](https://community.ibm.com/community/user/blogs/matthias-blomme/2023/05/23/ace-bar-build-commands-unraveling-the-differences)

If you don’t measure startup time, you’re just hoping it’s fast enough. Spoiler: it won’t be.


## Resource interference

You wouldn’t pack volatile chemicals next to fresh produce. If one leaks, everything’s toast. Same deal with runtimes. 
Put two unrelated applications in the same container and one bad actor can tank the whole thing.

A CPU spike in one flow means the other gets starved. A memory leak in some forgotten listener takes down your critical 
path. Or worse, one flow mounts a file system the other has no business even seeing. Now you’ve got an attack surface no 
one asked for.

If you can't explain, clearly and in one sentence, why two peas are in the same pod, they shouldn't be.
“Because we always did it that way” is **NOT** a reason. It's a red flag. If that’s your answer, stop what you’re doing and 
go fix it. And don’t say it out loud. Ever.

When in doubt, split. Isolation costs less than cleanup.


## 3. Bundling logic

Bundling isn’t inherently bad. But bundling for the wrong reasons will rot your runtime from the inside out.
The points below are just that: points. Not rules. Not guarantees. They’re starting positions. Use your brain.

Good reasons to bundle:
- They hit the same endpoint or interface and have the same criticality.
- They’re owned and operated by the same team. One team, one runtime is easier to live with.
- They’re a small set of resources that share a library and get updated together.
- They’re part of a bigger, tightly coupled setup that moves as one.
- They’re legacy apps with low change rates or a clear decommission plan. Keeping them together makes cleanup easy. 
No one wants to babysit a runtime for something that dies next quarter.

Bad reasons to bundle:
- You want to scale them differently.
- One is critical, the other isn’t. Don’t mix a payment flow with a reporting job and hope for the best.
- They handle data with different sensitivity levels.
- They’re loosely coupled and can fail independently. That’s a feature, not a flaw.
- You’re ignoring technical spillover. In ACE, if one app needs a feature, ibmint optimize keeps it on for all. One weird 
edge case, and nine other apps pay for it.
- You’re bundling out of convenience. Just because two flows came from the same BAR file doesn’t mean they belong together. 
That’s packaging, not architecture.
- You’re crossing team boundaries. If the apps don’t share ownership, support, or deployment cadence, you’re building in 
friction. Someone always ends up blocked.

If you can’t defend the bundle under fire, it’s not a bundle. It’s baggage.

## 4. Libraries and shared code

Shared code sounds smart. Until it drags half your runtime down with it.

It only makes sense to keep things together if they actually move together. If one flow needs a fix and you’re afraid to 
touch the lib because five others might break in the process, that’s not shared. That’s hostage-taking. Stockholm 
syndrome be damned.

It’s fine to keep flows together if they share a library and always get upgraded together. But don’t pretend one shared 
dependency means they belong in the same runtime.  If half your flows use one subflow and the other half use another? 
Don’t lump them together. Split the library and run two runtimes.

Libraries enable reuse, and that’s great. But when you're managing runtimes, the goal isn’t optimal reuse. It’s control.

## 5. Scaling strategy

We can keep this one short.

Scaling costs money. So be mindful. Don’t scale if you don’t need to. Next.

Whether it’s horizontal, vertical, or startup scaling (yes, that last one is a teaser, watch for a dedicated blog), 
if an application needs to scale, separate it from the rest. You don’t scale an app. You scale a container.

## 6. Security and data sensitivity

Not all data is created equal. And not all flows should live next to each other.

If one flow handles sensitive data and the other doesn’t, keep them apart. Don’t let a sloppy debug endpoint or overly 
verbose log expose your payroll system. Same goes for trust boundaries. If the security level isn't the same, split it. 
And if bundling makes audits harder to explain, it’s probably the wrong setup.

Security isn’t where you get clever. Keep things predictable and contained.Not all data is created equal. And not all 
flows should live next to each other.

If one flow handles sensitive data and the other doesn’t, keep them apart. Don’t let a sloppy debug endpoint or overly 
verbose log expose your payroll system. Same goes for trust boundaries. If the security level isn't the same, split it. 
And if bundling makes audits harder to explain, it’s probably the wrong setup.

Security isn’t where you get clever. Keep things predictable and contained.

## 7. Ownership and operations

A runtime is one unit. You restart it. You redeploy it. You roll it back. Everything inside gets hit.

So if multiple teams own different apps, don’t shove them into the same container. You’ll spend more time figuring out
who’s on call and when you're even allowed to fix the issue than actually fixing the issue. Different owners means 
different responsibilities. Keep those lines sharp.

Same goes for update strategy. You don’t patch a container. You rebuild it and restart it. That means even the untouched 
apps get bounced. If one team ships weekly and another ships quarterly, someone’s going to be caught in the crossfire.

Runtime boundaries should follow ownership and release patterns. If they don’t, enjoy the finger-pointing. If you ever 
find a patch window.

## 8. Coupling level

End to end chains that are tightly coupled and must move together can be grouped.

Loosely coupled pieces should not share a runtime. Independent failure is a feature, not a bug.

## 9. Build and release shape

Compile at build time. Keep runtime work minimal.

If you use fry, verify that the artifact that passed tests is the one you deploy.

If you use bake, you are wrong.

## 10. A few more worth adding

Licensing cost: more CPU usually means more PVU and more money. Include licensing in your scaling plan.

Observability and blast radius: if a runtime fails, which services and dashboards are down. Keep failure domains small.

Configuration variance: if two apps need very different config or secrets, it is a hint to split.

Upgrade cadence: if one piece changes weekly and another quarterly, consider separate runtimes.